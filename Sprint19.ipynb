{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sprint19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykenkou001/diveintocode-ml/blob/master/Sprint19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zo958VcYK7D",
        "colab_type": "code",
        "outputId": "9930be62-0a2d-452e-86b3-58a3b6771a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.6.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXtjf1M2vXgQ",
        "colab_type": "code",
        "outputId": "bac3ad90-e1e8-4f25-85b6-fd7f4a93bd13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D, ZeroPadding2D, Conv2DTranspose\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers import LeakyReLU, BatchNormalization, Activation, Dropout\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmusYUjgX5Rf",
        "colab_type": "code",
        "outputId": "21284eae-88f8-432b-a3de-8dbcd6f5d07c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz94s0BqX50p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir .kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOb2_xktYC8f",
        "colab_type": "code",
        "outputId": "47eba4a3-bc50-4b5d-e6a3-47c8bb40f6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls -a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m.\u001b[0m/  \u001b[01;34m..\u001b[0m/  \u001b[01;34m.config\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34m.kaggle\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbrlwyoYayv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/　へアクセスし、ログイン後に右上のプロフィール画像をクリック、さらに\"My Account\"をクリックする\n",
        "# このサイトの「API」項目にある\"Create New API Token\"をクリックすると、kaggle.jsonファイルが自動的にダウンロードされる\n",
        "# ローカルで、kaggle.json（ダウンロードフォルダにあるはず）をエディターで開く。\n",
        "# このセルの以下のコードにある token = {'username':'***','key':'***'} における「***」部分を、\n",
        "# ダウンロードしたkaggle.jsonを参照して書き換え、このセルを実行する\n",
        "\n",
        "import json\n",
        "\n",
        "token = {'username':'ykenkou001','key':'a6ed2f37d12c119c883b39e22183dadc'}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0YHd6LcbSJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /content/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E9gx_jSa9tJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erk54BOPbZdd",
        "colab_type": "code",
        "outputId": "8ddfa230-cf7d-4f6b-fe64-41c220410ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# simpsonデータセットのAPIcommandを叩いてデータセットをダウンロードする\n",
        "# APIcommandはこちらのサイトに。https://www.kaggle.com/alexattia/the-simpsons-characters-dataset\n",
        "\n",
        "!kaggle competitions download -c tgs-salt-identification-challenge"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "depths.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRC8vyl41mAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi9_AdA5oBSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT_EoanXb1C2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/test.zip -d test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Mv0wGwco13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train用のデータセットを解凍\n",
        "\n",
        "!unzip /content/train.zip -d train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG9pA-8D20wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data.py\n",
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np \n",
        "import os\n",
        "import glob\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "\n",
        "Sky = [128,128,128]\n",
        "Building = [128,0,0]\n",
        "Pole = [192,192,128]\n",
        "Road = [128,64,128]\n",
        "Pavement = [60,40,222]\n",
        "Tree = [128,128,0]\n",
        "SignSymbol = [192,128,128]\n",
        "Fence = [64,64,128]\n",
        "Car = [64,0,128]\n",
        "Pedestrian = [64,64,0]\n",
        "Bicyclist = [0,128,192]\n",
        "Unlabelled = [0,0,0]\n",
        "\n",
        "COLOR_DICT = np.array([Sky, Building, Pole, Road, Pavement,\n",
        "                          Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n",
        "\n",
        "\n",
        "def adjustData(img,mask,flag_multi_class,num_class):\n",
        "    if(flag_multi_class):\n",
        "        img = img / 255\n",
        "        mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n",
        "        new_mask = np.zeros(mask.shape + (num_class,))\n",
        "        for i in range(num_class):\n",
        "            #for one pixel in the image, find the class in mask and convert it into one-hot vector\n",
        "            #index = np.where(mask == i)\n",
        "            #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n",
        "            #new_mask[index_mask] = 1\n",
        "            new_mask[mask == i,i] = 1\n",
        "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
        "        mask = new_mask\n",
        "    elif(np.max(img) > 1):\n",
        "        img = img / 255\n",
        "        mask = mask /255\n",
        "        mask[mask > 0.5] = 1\n",
        "        mask[mask <= 0.5] = 0\n",
        "    return (img,mask)\n",
        "\n",
        "\n",
        "\n",
        "def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n",
        "                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n",
        "                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n",
        "    '''\n",
        "    can generate image and mask at the same time\n",
        "    use the same seed for image_datagen and mask_datagen to ensure the transformation for image and mask is the same\n",
        "    if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "    イメージとマスクを同時に生成できます。image_datagenとmask_datagenに同じシードを使用して、\n",
        "    ジェネレーターの結果を視覚化する場合にイメージとマスクの変換が同じであることを確認します。\n",
        "    save_to_dir= \"your path\"を設定します。\n",
        "    '''\n",
        "    #インスタンス化\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "    #ディレクトリから画像を読み込み、データを生成するジェネレーターを元画像用、\n",
        "    #mask用にそれぞれ作成する。\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [image_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = image_save_prefix,\n",
        "        seed = seed)\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        classes = [mask_folder],\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = mask_save_prefix,\n",
        "        seed = seed)\n",
        "    #image,mask画像をそれぞれ取り出し、データのサイズを調整する。\n",
        "    train_generator = zip(image_generator, mask_generator)\n",
        "    for (img,mask) in train_generator:\n",
        "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "        yield (img,mask)\n",
        "\n",
        "\n",
        "\n",
        "def testGenerator(test_path,num_image = 4000,target_size = (256,256),flag_multi_class = False,as_gray = True):\n",
        "    #testdataのファイルを読み込めるようにし、resize, reshapeする。\n",
        "    test_image_path_list = glob.glob(test_path+\"/*\")\n",
        "    for i in range(num_image):\n",
        "      #画像サイズの読み込み\n",
        "        img = io.imread(test_image_path_list[i], as_gray = as_gray)\n",
        "        img = img / 255\n",
        "        img = trans.resize(img,target_size)\n",
        "        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
        "        img = np.reshape(img,(1,)+img.shape)\n",
        "        #莫大な量の戻り値を小分けにして返す\n",
        "        yield img\n",
        "\n",
        "\n",
        "def geneTrainNpy(image_path,mask_path,flag_multi_class = False,num_class = 2,image_prefix = \"image\",mask_prefix = \"mask\",image_as_gray = True,mask_as_gray = True):\n",
        "    image_name_arr = glob.glob(os.path.join(image_path,\"%s*.png\"%image_prefix))\n",
        "    image_arr = []\n",
        "    mask_arr = []\n",
        "    for index,item in enumerate(image_name_arr):\n",
        "        img = io.imread(item,as_gray = image_as_gray)\n",
        "        img = np.reshape(img,img.shape + (1,)) if image_as_gray else img\n",
        "        mask = io.imread(item.replace(image_path,mask_path).replace(image_prefix,mask_prefix),as_gray = mask_as_gray)\n",
        "        mask = np.reshape(mask,mask.shape + (1,)) if mask_as_gray else mask\n",
        "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
        "        image_arr.append(img)\n",
        "        mask_arr.append(mask)\n",
        "    image_arr = np.array(image_arr)\n",
        "    mask_arr = np.array(mask_arr)\n",
        "    return image_arr,mask_arr\n",
        "\n",
        "\n",
        "def labelVisualize(num_class,color_dict,img):\n",
        "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
        "    img_out = np.zeros(img.shape + (3,))\n",
        "    for i in range(num_class):\n",
        "        img_out[img == i,:] = color_dict[i]\n",
        "    return img_out / 255\n",
        "\n",
        "\n",
        "\n",
        "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
        "    for i,item in enumerate(npyfile):\n",
        "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
        "        io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJCmRHeFTAJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.py\n",
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis = 3)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 3)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 3)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "    model = Model(input = inputs, output = conv10)\n",
        "\n",
        "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    \n",
        "    model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "    \tmodel.load_weights(pretrained_weights)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCYSPzkhBudt",
        "colab_type": "text"
      },
      "source": [
        "**コードリーディング**\n",
        "\n",
        "*   kerasで書かれており、入力画像サイズは256×256、ゼロパディングで入力画像サイズと出力サイズは同じ。  \n",
        "* 活性化関数はreluで重み初期化方法はHe_normal。  \n",
        "*  U-netの階層は４。  \n",
        "*  U-Netのencoder部分ではサイズ3×3のカーネルで2つの畳み込み層があり、その後のPooling層ではMaxPoolingしてpool_size(2, 2)なので水平、垂直方向の次元でサイズが半分になる。\n",
        "*　encoderの最後の部分では過学習を防止するためdropout技法を使用、その後、Pooling層があり、MaxPoolingして各次元数を半分にしている。\n",
        "*  階層4～0までのフィルター枚数の変化は64→128→256→512。\n",
        "*　U-Netの底の階層では、データのshapeが16×16でフィルター数1024のカーネルサイズ3×3の畳み込み層が2つあり、その後過学習を防ぐためdropout技法を使用している。\n",
        "*　decoder部分に入り、各次元のshapeを倍に（upsampling）し、その後1つの畳み込み層があり、encoderの4層目とdecoderの4層目を結合し（Contracting path）し、2つの畳み込み層を通している。同じ作業を最上層まで繰り返している。\n",
        "*　出力層では活性化関数sofomaxを使い出力している。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5CwUJ3H6rXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6_VxvqHlFNc",
        "colab_type": "text"
      },
      "source": [
        "***学習・推定***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ad11aaeb-b28a-4313-def2-95083a72428a",
        "id": "5aQgd60rDQSP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#main.py\n",
        "# from model import *\n",
        "# from data import *\n",
        "\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "\n",
        "data_gen_args = dict(rotation_range=0.2,\n",
        "                    width_shift_range=0.05,\n",
        "                    height_shift_range=0.05,\n",
        "                    shear_range=0.05,\n",
        "                    zoom_range=0.05,\n",
        "                    horizontal_flip=True,\n",
        "                    fill_mode='nearest')\n",
        "myGene = trainGenerator(2,'/content/drive/My Drive/U-net/train','images','masks',data_gen_args,save_to_dir ='/content/drive/My Drive/U-net/create_pic' )\n",
        "\n",
        "model = unet()\n",
        "model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=False)\n",
        "model.fit_generator(myGene,steps_per_epoch=300,epochs=5,callbacks=[model_checkpoint])\n",
        "\n",
        "testGene = testGenerator(\"/content/drive/My Drive/U-net/test/images\")\n",
        "results = model.predict_generator(testGene,30,verbose=1)\n",
        "saveResult(\"/content/drive/My Drive/U-net/test/predict_file\",results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 64) 640         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 64) 36928       conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 128 147584      conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 512)  0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 1024) 9438208     conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 16, 16, 1024) 0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 1024) 0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           conv2d_6[0][0]                   \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 128, 128, 256 0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 128, 128, 128 295040      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 128, 128, 128 147584      conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 256, 256, 128 0           conv2d_2[0][0]                   \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 256, 256, 1)  3           conv2d_23[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 31,031,685\n",
            "Trainable params: 31,031,685\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "Found 4000 images belonging to 1 classes.\n",
            "Found 4000 images belonging to 1 classes.\n",
            "300/300 [==============================] - 147s 489ms/step - loss: 0.6123 - acc: 0.7378\n",
            "\n",
            "Epoch 00001: saving model to unet_membrane.hdf5\n",
            "Epoch 2/5\n",
            "300/300 [==============================] - 136s 454ms/step - loss: 0.5791 - acc: 0.7460\n",
            "\n",
            "Epoch 00002: saving model to unet_membrane.hdf5\n",
            "Epoch 3/5\n",
            "300/300 [==============================] - 136s 455ms/step - loss: 0.5416 - acc: 0.7630\n",
            "\n",
            "Epoch 00003: saving model to unet_membrane.hdf5\n",
            "Epoch 4/5\n",
            "300/300 [==============================] - 147s 491ms/step - loss: 0.5229 - acc: 0.7560\n",
            "\n",
            "Epoch 00004: saving model to unet_membrane.hdf5\n",
            "Epoch 5/5\n",
            "300/300 [==============================] - 1069s 4s/step - loss: 0.5297 - acc: 0.7430\n",
            "\n",
            "Epoch 00005: saving model to unet_membrane.hdf5\n",
            "30/30 [==============================] - 17s 580ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/0_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/1_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/2_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/3_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/4_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/5_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/6_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/7_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/8_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/9_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/10_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/11_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/12_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/13_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/14_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/15_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/16_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/17_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/18_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/19_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/20_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/21_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/22_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/23_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/24_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/25_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/26_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/27_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/28_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py:141: UserWarning: /content/drive/My Drive/U-net/test/predict_file/29_predict.png is a low contrast image\n",
            "  warn('%s is a low contrast image' % fname)\n",
            "WARNING:root:Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZftCk588dKvH",
        "colab_type": "code",
        "outputId": "59ec8f41-1f12-44fa-e9d1-af8da9115919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "print(\"テスト画像\")\n",
        "display_png(Image('/content/drive/My Drive/U-net/test/images/0005bb9630.png'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "テスト画像\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGUAAABlCAIAAADbHrqYAAAsFUlEQVR4nFXd15bjxpI1YBAAvS/b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\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4f7uFIFbIxR",
        "colab_type": "code",
        "outputId": "9dad3e9a-097d-4d11-b0b4-8c95df5e5832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "from IPython.display import Image,display_png\n",
        "\n",
        "print(\"出力結果\")\n",
        "display_png(Image('/content/drive/My Drive/U-net/test/predict_file/0_predict.png'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "出力結果\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAByElEQVR42u3cwUrDUBAF0JlpWhda\nxI07V/3/j1MoQmkzrl0IEhDUOfcDQuYwL5m8kMTLvjKGJrNOsR9bfkREPtctRgOcq3syQF9rdANE\nr8MBYq0eLjC9A3o6QAAAAAAAABn8NGQJAAAAAAAAAAAAADAK6wAAAAAAAAAAAAAAAAAAAAAAgEyI\nHSEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABgTrwXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgPyn+GoMAAAAAAAAAAAAAAAAAAAAADAuNkQA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgfyn+KgsAAAAAAAAAAADAKKwDAAAA\nAADAPIDUAQahyfXrgIp0DRhd//C7QOaSET24/lx2cR0rkFlVu8zInFr/YVke+v3S3dsWwtbW+QXg\nGVXL8fG8nF7fLuut1zU+K/SXZfbPntf29HePlxGZtdwd7p+OH3c8KLukYnTNAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6v8-X-8cksj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}