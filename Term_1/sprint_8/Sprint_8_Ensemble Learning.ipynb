{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import (GridSearchCV, KFold, cross_val_score,\n",
    "                                     train_test_split)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\") # データをダウンロード\n",
    "X = df[['GrLivArea', 'YearBuilt']] # 2つの特徴量を抜き出し変数に格納\n",
    "y = df[['SalePrice']] # 目的変数を抜き出し、変数に格納\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 対数変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#対数変換処理をする\n",
    "X_train_log = np.log(X_train)\n",
    "y_train_log = np.log(y_train)\n",
    "X_test_log = np.log(X_test)\n",
    "y_test_log = np.log(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 【問題1】ブレンディングのスクラッチ実装\n",
    "ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習・推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "svm = SVR(gamma='scale', C=1.0, epsilon=0.2) # SVCに訓練データを学習させる\n",
    "svm.fit(X_train_log, y_train_log.values.ravel()) # SVCによる検証データの分類\n",
    "svm_predict = svm.predict(X_test_log) #推定\n",
    "svm_mse = mean_squared_error(y_test_log, svm_predict) #mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定木\n",
    "dtr = DecisionTreeRegressor(max_depth=3)\n",
    "dtr.fit(X_train_log, y_train_log)#学習\n",
    "dtr_predict = dtr.predict(X_test_log)#推定\n",
    "dtr_mse = mean_squared_error(y_test_log, dtr_predict) #mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#線形回帰\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_log, y_train_log)#学習\n",
    "lr_predict = lr.predict(X_test_log)#推定\n",
    "lr_mse = mean_squared_error(y_test_log, lr_predict) #mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>単一モデルのMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.052578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>決定木</th>\n",
       "      <td>0.071384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>線形回帰</th>\n",
       "      <td>0.044795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      単一モデルのMSE\n",
       "SVM    0.052578\n",
       "決定木    0.071384\n",
       "線形回帰   0.044795"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#単一モデルの精度\n",
    "score = pd.DataFrame([[svm_mse], [dtr_mse], [lr_mse]], columns={'単一モデルのMSE'}, index=['SVM', '決定木', '線形回帰'])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 平均をとる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blend_1_mse 0.05054710577445747\n"
     ]
    }
   ],
   "source": [
    "#単一モデルの精度結果をもとに平均をとる\n",
    "blend_1 = (svm_predict.reshape(-1, 1)+ dtr_predict.reshape(-1, 1) + lr_predict.reshape(-1, 1))/3\n",
    "#MSE\n",
    "blend_1_mse = mean_squared_error(y_test_log, blend_1) #mse\n",
    "print('blend_1_mse',blend_1_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 各モデルに重みを付ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blend_2_mse 0.051326980571388625\n"
     ]
    }
   ],
   "source": [
    "blend_2 = (svm_predict.reshape(-1, 1)*0.5 + dtr_predict.reshape(-1,1)*0.3 + lr_predict.reshape(-1,1)*0.2)\n",
    "#mse\n",
    "blend_2_mse = mean_squared_error(y_test_log, blend_2)\n",
    "print('blend_2_mse',blend_2_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.SVMのカーネルの変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel='poly'\n",
    "svm_1 = SVR(kernel='poly', gamma='auto') # SVCに訓練データを学習させる\n",
    "svm_1.fit(X_train_log, y_train_log.values.ravel()) # SVCによる検証データの分類\n",
    "svm_1_predict = svm_1.predict(X_test_log) #推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#kernel='sigmoid'\n",
    "svm_2 = SVR(kernel='sigmoid', gamma='auto') # SVCに訓練データを学習させる\n",
    "svm_2.fit(X_train_log, y_train_log.values.ravel()) # SVCによる検証データの分類\n",
    "svm_2_predict = svm_2.predict(X_test_log) #推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blend_3_mse 0.061561642606966886\n"
     ]
    }
   ],
   "source": [
    "blend_3 = (svm_1_predict.reshape(-1, 1) + svm_2_predict.reshape(-1, 1) + svm_predict.reshape(-1, 1))/3\n",
    "#mse\n",
    "blend_3_mse = mean_squared_error(y_test_log, blend_3)\n",
    "print('blend_3_mse', blend_3_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SVMにグリッドサーチをかけ,パラメーターチューニングを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='scale', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svr = SVR(gamma=\"scale\")\n",
    "gs = GridSearchCV(svr, parameters, cv=5)\n",
    "gs.fit(X_train_log, y_train_log.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.701688117080102\n",
      "Best parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "Best cross-validation: 0.711107903019747\n"
     ]
    }
   ],
   "source": [
    "#結果の出力\n",
    "print('Test set score: {}'.format(gs.score(X_test_log, y_test_log)))\n",
    "print('Best parameters: {}'.format(gs.best_params_))\n",
    "print('Best cross-validation: {}'.format(gs.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#グリッドサーチの結果を学習に適用する\n",
    "svm_3 = SVR(gamma='scale',C=10, kernel='rbf') # SVCに訓練データを学習させる\n",
    "svm_3.fit(X_train_log, y_train_log.values.ravel()) # SVCによる検証データの分類\n",
    "svm_3_predict = svm_3.predict(X_test_log) #推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blend_4_mse 0.06155771559672392\n"
     ]
    }
   ],
   "source": [
    "blend_4 = (svm_3_predict.reshape(-1,1) + svm_2_predict.reshape(-1,1) + svm_1_predict.reshape(-1,1))/3\n",
    "#mse\n",
    "blend_4_mse = mean_squared_error(y_test_log, blend_4)\n",
    "print('blend_4_mse', blend_4_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 決定木にグリッドサーチをかけ,パラメーターチューニングを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeRegressor(criterion='mse', max_depth=None,\n",
       "                                             max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort=False, random_state=None,\n",
       "                                             splitter='best'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [2, 4, 6, 8, 10],\n",
       "                         'min_samples_leaf': [1, 5, 8],\n",
       "                         'min_samples_split': [2, 3, 5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"max_depth\": [2,4,6,8,10],\n",
    "              \"min_samples_split\": [2, 3, 5],\n",
    "              \"min_samples_leaf\": [1,5,8]}\n",
    "\n",
    "gs = GridSearchCV(estimator=DecisionTreeRegressor(),\n",
    "                 param_grid = param_grid,   \n",
    "                 scoring='neg_mean_squared_error', \n",
    "                  cv=5)\n",
    "\n",
    "gs.fit(X_train_log, y_train_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: -0.049533236634605675\n",
      "Best parameters: {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 3}\n",
      "Best cross-validation: -0.04615085963671587\n"
     ]
    }
   ],
   "source": [
    "#結果の出力\n",
    "print('Test set score: {}'.format(gs.score(X_test_log, y_test_log)))\n",
    "print('Best parameters: {}'.format(gs.best_params_))\n",
    "print('Best cross-validation: {}'.format(gs.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定木(パラメーターチューニングしたものを使用)\n",
    "dtr_1 = DecisionTreeRegressor(max_depth=6, min_samples_leaf=8, min_samples_split=2)\n",
    "dtr_1.fit(X_train_log, y_train_log)#学習\n",
    "dtr_1_predict = dtr_1.predict(X_test_log)#推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blend_5_mse 0.04309929579367665\n"
     ]
    }
   ],
   "source": [
    "blend_5 = (dtr_1_predict.reshape(-1, 1)+svm_1_predict.reshape(-1, 1)+lr_predict)/3\n",
    "#mse\n",
    "blend_5_mse = mean_squared_error(y_test_log, blend_5)\n",
    "print(\"blend_5_mse\", blend_5_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>平均をとる</th>\n",
       "      <td>0.050547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>重み付け</th>\n",
       "      <td>0.051327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMカーネル変更</th>\n",
       "      <td>0.061562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS_SVM</th>\n",
       "      <td>0.061558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS_決定木</th>\n",
       "      <td>0.043099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                MSE\n",
       "平均をとる      0.050547\n",
       "重み付け       0.051327\n",
       "SVMカーネル変更  0.061562\n",
       "GS_SVM     0.061558\n",
       "GS_決定木     0.043099"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>単一モデルのMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.052578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>決定木</th>\n",
       "      <td>0.071384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>線形回帰</th>\n",
       "      <td>0.044795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      単一モデルのMSE\n",
       "SVM    0.052578\n",
       "決定木    0.071384\n",
       "線形回帰   0.044795"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ブレンディングの精度\n",
    "score_1 = pd.DataFrame([[blend_1_mse], \n",
    "                      [blend_2_mse], \n",
    "                      [blend_3_mse],\n",
    "                     [blend_4_mse],\n",
    "                     [blend_5_mse]], columns={'MSE'}, index=['平均をとる', '重み付け', 'SVMカーネル変更', 'GS_SVM', 'GS_決定木'])\n",
    "display(score_1)\n",
    "display(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【考察】単一モデルでは線形回帰が最も低く、ブレンディングでは「平均をとったもの」、「重み付けをしたもの」、「グリッドサーチで決定木のパラメーターチューニングをしたもの」が低い値が出た。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】バギングのスクラッチ実装\n",
    "バギング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
    "\n",
    "バギングとは  \n",
    "バギングは入力データの選び方を多様化する方法です。学習データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ ブートストラップサンプル ）を作り出します。それらによってモデルをN個学習し、推定結果の平均をとります。ブレンディングと異なり、それぞれの重み付けを変えることはありません。\n",
    "\n",
    "sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation\n",
    "\n",
    "scikit-learnのtrain_test_splitを、shuffleパラメータをTrueにして使うことで、ランダムにデータを分割することができます。これによりブートストラップサンプルが手に入ります。\n",
    "\n",
    "推定結果の平均をとる部分はブースティングと同様の実装になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SVM\n",
    "# svm = SVR(gamma='scale', C=1.0, epsilon=0.2) # SVCに訓練データを学習させる\n",
    "# svm.fit(X_train_log, y_train_log) # SVCによる検証データの分類\n",
    "# svm_predict = svm.predict(X_test_log) #推定\n",
    "# svm_msxe = mean_squared_error(y_test_log, svm_predict) #mse\n",
    "# print(svm_predict.shape)\n",
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "バギング結果、MSE_svmは0.048992\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "#推定結果を格納するリスト\n",
    "SVM_zero = np.zeros_like(y_test_log).ravel()\n",
    "m = 30\n",
    "\n",
    "for i in range(m):\n",
    "    #学習データをランダムに抽出\n",
    "    new_X_train, _, new_y_train, _ = train_test_split(X_train_log, y_train_log, shuffle=True, train_size=0.8)\n",
    "    # SVMに訓練データを学習させる\n",
    "    svm = SVR(gamma='scale', C=10, epsilon=0.2)\n",
    "    # SVMによる検証データの分類\n",
    "    svm.fit(new_X_train, new_y_train.values.ravel())\n",
    "    #推定\n",
    "    svm_predict = svm.predict(X_test_log)\n",
    "    #リストに足し上げていく\n",
    "    SVM_zero += svm_predict.ravel()\n",
    "\n",
    "#推定結果の平均を出す\n",
    "predict_mean = SVM_zero/m\n",
    "y_test_log = y_test_log\n",
    "\n",
    "\n",
    "#mse\n",
    "mse_svm = mean_squared_error(y_test_log, predict_mean)\n",
    "#print\n",
    "    \n",
    "print(\"バギング結果、MSE_svmは{:.6f}\".format(mse_svm))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "バギング結果、MSE_lrは0.044795\n"
     ]
    }
   ],
   "source": [
    "#線形回帰\n",
    "\n",
    "#推定結果を格納するリスト\n",
    "lr_zero = np.zeros_like(y_test_log).ravel()\n",
    "m = 10\n",
    "\n",
    "for i in range(m):\n",
    "    #学習データをランダムに抽出\n",
    "    new_X_train, _, new_y_train, _ = train_test_split(X_train_log, y_train_log, shuffle=True, train_size=0.8)\n",
    "    #訓練データを学習させる\n",
    "    lr = LinearRegression()\n",
    "    # SVMによる検証データの分類\n",
    "    lr.fit(X_train_log, y_train_log)#学習\n",
    "    #推定\n",
    "    lr_predict = lr.predict(X_test_log)#推定\n",
    "\n",
    "    #リストに足し上げていく\n",
    "    lr_zero += lr_predict.ravel()\n",
    "\n",
    "#推定結果の平均を出す\n",
    "predict_mean_lr = lr_zero/m\n",
    "#mse\n",
    "mse_lr = mean_squared_error(y_test_log, predict_mean_lr)\n",
    "#print\n",
    "    \n",
    "print(\"バギング結果、MSE_lrは{:.6f}\".format(mse_lr))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 決定木"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "バギング結果、MSE_dtrは0.049163\n"
     ]
    }
   ],
   "source": [
    "#決定木\n",
    "\n",
    "#推定結果を格納するリスト\n",
    "dtr_zero = np.zeros_like(y_test_log).ravel()\n",
    "m = 10\n",
    "\n",
    "for i in range(m):\n",
    "    #学習データをランダムに抽出\n",
    "    new_X_train, _, new_y_train, _ = train_test_split(X_train_log, y_train_log, shuffle=True, train_size=0.8)\n",
    "    #訓練データを学習させる\n",
    "    dtr = DecisionTreeRegressor(max_depth=6, min_samples_leaf=5)\n",
    "    # SVMによる検証データの分類\n",
    "    dtr.fit(X_train_log, y_train_log)#学習\n",
    "    #推定\n",
    "    dtr_predict = dtr.predict(X_test_log)#推定\n",
    "\n",
    "    #リストに足し上げていく\n",
    "    dtr_zero += dtr_predict.ravel()\n",
    "\n",
    "#推定結果の平均を出す\n",
    "predict_mean_dtr = dtr_zero/m\n",
    "#mse\n",
    "mse_dtr = mean_squared_error(y_test_log, predict_mean_dtr)\n",
    "#print\n",
    "    \n",
    "print(\"バギング結果、MSE_dtrは{:.6f}\".format(mse_dtr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>バギングMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.048992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>線形回帰</th>\n",
       "      <td>0.044795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>決定木</th>\n",
       "      <td>0.049163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       バギングMSE\n",
       "SVM   0.048992\n",
       "線形回帰  0.044795\n",
       "決定木   0.049163"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>単一モデルのMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.052578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>決定木</th>\n",
       "      <td>0.071384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>線形回帰</th>\n",
       "      <td>0.044795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      単一モデルのMSE\n",
       "SVM    0.052578\n",
       "決定木    0.071384\n",
       "線形回帰   0.044795"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_2 = pd.DataFrame([[mse_svm],\n",
    "                        [mse_lr],\n",
    "                        [mse_dtr]], columns=['バギングMSE'], index={'SVM', '線形回帰', '決定木'} )\n",
    "display(score_2)\n",
    "display(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【考察】決定木とSVMでバギングを行ったものが単一モデルよりも精度が良かった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】スタッキングのスクラッチ実装\n",
    "スタッキング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
    "\n",
    "スタッキングとは\n",
    "スタッキングの手順は以下の通りです。最低限ステージ0とステージ1があればスタッキングは成立するため、それを実装してください。まずは \n",
    "K\n",
    "0\n",
    "=\n",
    "3\n",
    ",\n",
    "M\n",
    "0\n",
    "=\n",
    "2\n",
    " 程度にします。\n",
    "\n",
    "《学習時》\n",
    "\n",
    "（ステージ \n",
    "0\n",
    " ）\n",
    "\n",
    "学習データを \n",
    "K\n",
    "0\n",
    " 個に分割する。\n",
    "分割した内の \n",
    "(\n",
    "K\n",
    "0\n",
    "−\n",
    "1\n",
    ")\n",
    " 個をまとめて学習用データ、残り \n",
    "1\n",
    " 個を推定用データとする組み合わせが \n",
    "K\n",
    "0\n",
    " 個作れる。\n",
    "あるモデルのインスタンスを \n",
    "K\n",
    "0\n",
    " 個用意し、異なる学習用データを使い学習する。\n",
    "それぞれの学習済みモデルに対して、使っていない残り \n",
    "1\n",
    " 個の推定用データを入力し、推定値を得る。（これをブレンドデータと呼ぶ）\n",
    "さらに、異なるモデルのインスタンスも \n",
    "K\n",
    "0\n",
    " 個用意し、同様のことを行う。モデルが \n",
    "M\n",
    "0\n",
    " 個あれば、 \n",
    "M\n",
    "0\n",
    " 個のブレンドデータが得られる。\n",
    "（ステージ \n",
    "n\n",
    " ）\n",
    "\n",
    "ステージ \n",
    "n\n",
    "−\n",
    "1\n",
    " のブレンドデータを\n",
    "M\n",
    "n\n",
    "−\n",
    "1\n",
    " 次元の特徴量を持つ学習用データと考え、 \n",
    "K\n",
    "n\n",
    " 個に分割する。以下同様である。\n",
    "（ステージ \n",
    "N\n",
    " ）＊最後のステージ\n",
    "\n",
    "ステージ \n",
    "N\n",
    "−\n",
    "1\n",
    " の \n",
    "M\n",
    "N\n",
    "−\n",
    "1\n",
    " 個のブレンドデータを\n",
    "M\n",
    "N\n",
    "−\n",
    "1\n",
    "次元の特徴量の入力として、1種類のモデルの学習を行う。これが最終的な推定を行うモデルとなる。\n",
    "《推定時》\n",
    "\n",
    "（ステージ \n",
    "0\n",
    " ）\n",
    "\n",
    "テストデータを \n",
    "K\n",
    "0\n",
    "×\n",
    "M\n",
    "0\n",
    " 個の学習済みモデルに入力し、\n",
    "K\n",
    "0\n",
    "×\n",
    "M\n",
    "0\n",
    " 個の推定値を得る。これを \n",
    "K\n",
    "0\n",
    " の軸で平均値を求め \n",
    "M\n",
    "0\n",
    " 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "（ステージ \n",
    "n\n",
    " ）\n",
    "\n",
    "ステージ \n",
    "n\n",
    "−\n",
    "1\n",
    " で得たブレンドテストを \n",
    "K\n",
    "n\n",
    "×\n",
    "M\n",
    "n\n",
    " 個の学習済みモデルに入力し、\n",
    "K\n",
    "n\n",
    "×\n",
    "M\n",
    "n\n",
    " 個の推定値を得る。これを \n",
    "K\n",
    "n\n",
    " の軸で平均値を求め \n",
    "M\n",
    "0\n",
    " 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "（ステージ \n",
    "N\n",
    " ）＊最後のステージ\n",
    "\n",
    "ステージ \n",
    "N\n",
    "−\n",
    "1\n",
    " で得たブレンドテストを学習済みモデルに入力し、推定値を得る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> import numpy as np\n",
    "# >>> from sklearn.model_selection import KFold\n",
    "# >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "# >>> y = np.array([1, 2, 3, 4])\n",
    "# >>> kf = KFold(n_splits=2)\n",
    "# >>> kf.get_n_splits(X)\n",
    "# 2\n",
    "# >>> print(kf)  \n",
    "# KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "# >>> for train_index, test_index in kf.split(X):\n",
    "# ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "# ...    X_train, X_test = X[train_index], X[test_index]\n",
    "# ...    y_train, y_test = y[train_index], y[test_index]\n",
    "# TRAIN: [2 3] TEST: [0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 決定木\n",
    "dtr = DecisionTreeRegressor(max_depth=3)\n",
    "dtr.fit(X_train_log, y_train_log)#学習\n",
    "dtr_predict = dtr.predict(X_test_log)#推定\n",
    "dtr_mse = mean_squared_error(y_test_log, dtr_predict) #mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "svm = SVR(gamma='scale', C=1.0, epsilon=0.2) # SVCに訓練データを学習させる\n",
    "svm.fit(X_train_log, y_train_log.values.ravel()) # SVCによる検証データの分類\n",
    "svm_predict = svm.predict(X_test_log) #推定\n",
    "svm_mse = mean_squared_error(y_test_log, svm_predict) #mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#線形回帰\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_log, y_train_log)#学習\n",
    "lr_predict = lr.predict(X_test_log)#推定\n",
    "lr_mse = mean_squared_error(y_test_log, lr_predict) #mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "mylist = list(range(4))\n",
    "print(mylist)\n",
    "print(mylist[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     GrLivArea  YearBuilt\n",
      "0         1710       2003\n",
      "1         1262       1976\n",
      "2         1786       2001\n",
      "3         1717       1915\n",
      "4         2198       2000\n",
      "5         1362       1993\n",
      "6         1694       2004\n",
      "7         2090       1973\n",
      "8         1774       1931\n",
      "9         1077       1939\n",
      "10        1040       1965\n",
      "11        2324       2005\n",
      "12         912       1962\n",
      "13        1494       2006\n",
      "14        1253       1960\n",
      "15         854       1929\n",
      "16        1004       1970\n",
      "17        1296       1967\n",
      "18        1114       2004\n",
      "19        1339       1958\n",
      "20        2376       2005\n",
      "21        1108       1930\n",
      "22        1795       2002\n",
      "23        1060       1976\n",
      "24        1060       1968\n",
      "25        1600       2007\n",
      "26         900       1951\n",
      "27        1704       2007\n",
      "28        1600       1957\n",
      "29         520       1927\n",
      "..         ...        ...\n",
      "335       1786       1965\n",
      "336       1922       2005\n",
      "337       1536       2002\n",
      "338       1621       1984\n",
      "339       1215       1958\n",
      "340       1908       2002\n",
      "341        841       1950\n",
      "342       1040       1949\n",
      "343       1684       2005\n",
      "344       1112       1976\n",
      "345       1577       1939\n",
      "346        958       1960\n",
      "347       1478       1960\n",
      "348       1626       2003\n",
      "349       2728       2005\n",
      "350       1869       2007\n",
      "351       1453       1986\n",
      "352       1111       1941\n",
      "353        720       1928\n",
      "354       1595       1940\n",
      "355       1200       1995\n",
      "356       1167       1992\n",
      "357       1142       1976\n",
      "358       1352       1958\n",
      "359       1924       1998\n",
      "360        912       1978\n",
      "361       1505       1940\n",
      "362       1922       2003\n",
      "363        987       1972\n",
      "364       1574       1976\n",
      "\n",
      "[365 rows x 2 columns],      GrLivArea  YearBuilt\n",
      "365       1344       1920\n",
      "366       1394       1963\n",
      "367       1431       1962\n",
      "368       1268       1954\n",
      "369       1287       1959\n",
      "370       1664       2000\n",
      "371       1588       1959\n",
      "372        752       1984\n",
      "373       1319       1953\n",
      "374       1928       2003\n",
      "375        904       1922\n",
      "376        914       1996\n",
      "377       2466       2004\n",
      "378       1856       2010\n",
      "379       1800       2000\n",
      "380       1691       1924\n",
      "381       1301       2006\n",
      "382       1797       2006\n",
      "383        784       1928\n",
      "384       1953       1992\n",
      "385       1269       2004\n",
      "386       1184       1910\n",
      "387       1125       1976\n",
      "388       1479       1999\n",
      "389       2332       2007\n",
      "390       1367       1900\n",
      "391       1961       2001\n",
      "392        882       1959\n",
      "393        788       1941\n",
      "394       1034       1940\n",
      "..         ...        ...\n",
      "700       1800       2002\n",
      "701       1164       1969\n",
      "702       2576       2006\n",
      "703       1812       1900\n",
      "704       1484       2004\n",
      "705       1092       1930\n",
      "706       1824       1971\n",
      "707       1324       2006\n",
      "708       1456       2007\n",
      "709        904       1966\n",
      "710        729       1935\n",
      "711       1178       1900\n",
      "712       1228       1988\n",
      "713        960       1970\n",
      "714       1479       1976\n",
      "715       1350       1974\n",
      "716       2554       1890\n",
      "717       1178       1973\n",
      "718       2418       1993\n",
      "719        971       1969\n",
      "720       1742       1985\n",
      "721        848       2004\n",
      "722        864       1970\n",
      "723       1470       1954\n",
      "724       1698       2007\n",
      "725        864       1970\n",
      "726       1680       1988\n",
      "727       1232       2007\n",
      "728       1776       1958\n",
      "729       1208       1925\n",
      "\n",
      "[365 rows x 2 columns],       GrLivArea  YearBuilt\n",
      "730        1616       1995\n",
      "731        1146       2003\n",
      "732        2031       1998\n",
      "733        1144       1961\n",
      "734         948       1968\n",
      "735        1768       1914\n",
      "736        1040       1950\n",
      "737        1801       2005\n",
      "738        1200       1987\n",
      "739        1728       2004\n",
      "740        1432       1910\n",
      "741         912       1961\n",
      "742        1349       2000\n",
      "743        1464       1963\n",
      "744        1337       1993\n",
      "745        2715       1976\n",
      "746        2256       2000\n",
      "747        2640       1880\n",
      "748        1720       1996\n",
      "749        1529       1945\n",
      "750        1140       1910\n",
      "751        1320       2003\n",
      "752        1494       1997\n",
      "753        2098       2005\n",
      "754        1026       1969\n",
      "755        1471       1999\n",
      "756        1768       2007\n",
      "757        1386       1978\n",
      "758        1501       1999\n",
      "759        2531       1995\n",
      "...         ...        ...\n",
      "1065       2260       1996\n",
      "1066       1571       1993\n",
      "1067       1611       1964\n",
      "1068       2521       1973\n",
      "1069        893       1949\n",
      "1070       1048       1956\n",
      "1071       1556       1968\n",
      "1072       1456       1948\n",
      "1073       1426       1977\n",
      "1074       1240       2006\n",
      "1075       1740       1940\n",
      "1076       1466       1936\n",
      "1077       1096       1969\n",
      "1078        848       2004\n",
      "1079        990       1994\n",
      "1080       1258       1971\n",
      "1081       1040       1963\n",
      "1082       1459       2002\n",
      "1083       1251       1964\n",
      "1084       1498       1995\n",
      "1085        996       1992\n",
      "1086       1092       1973\n",
      "1087       1953       2005\n",
      "1088       1709       2004\n",
      "1089       1247       2005\n",
      "1090       1040       1950\n",
      "1091       1252       1999\n",
      "1092       1694       1925\n",
      "1093       1200       1965\n",
      "1094        936       1956\n",
      "\n",
      "[365 rows x 2 columns],       GrLivArea  YearBuilt\n",
      "1095       1314       2006\n",
      "1096       1355       1914\n",
      "1097       1088       1986\n",
      "1098       1324       1936\n",
      "1099       1601       1978\n",
      "1100        438       1920\n",
      "1101        950       1971\n",
      "1102       1134       1960\n",
      "1103       1194       1959\n",
      "1104       1302       1970\n",
      "1105       2622       1994\n",
      "1106       1442       1990\n",
      "1107       2021       2006\n",
      "1108       1690       2000\n",
      "1109       1836       2004\n",
      "1110       1658       1995\n",
      "1111       1964       1976\n",
      "1112        816       1957\n",
      "1113       1008       1953\n",
      "1114        833       1954\n",
      "1115       1734       2007\n",
      "1116       1419       2002\n",
      "1117        894       1967\n",
      "1118       1601       1958\n",
      "1119       1040       1959\n",
      "1120       1012       1920\n",
      "1121       1552       2005\n",
      "1122        960       1956\n",
      "1123        698       1947\n",
      "1124       1482       1992\n",
      "...         ...        ...\n",
      "1430       1838       2005\n",
      "1431        958       1976\n",
      "1432        968       1927\n",
      "1433       1792       2000\n",
      "1434       1126       1977\n",
      "1435       1537       1962\n",
      "1436        864       1971\n",
      "1437       1932       2008\n",
      "1438       1236       1957\n",
      "1439       1725       1979\n",
      "1440       2555       1922\n",
      "1441        848       2004\n",
      "1442       2007       2008\n",
      "1443        952       1916\n",
      "1444       1422       2004\n",
      "1445        913       1966\n",
      "1446       1188       1962\n",
      "1447       2090       1995\n",
      "1448       1346       1910\n",
      "1449        630       1970\n",
      "1450       1792       1974\n",
      "1451       1578       2008\n",
      "1452       1072       2005\n",
      "1453       1140       2006\n",
      "1454       1221       2004\n",
      "1455       1647       1999\n",
      "1456       2073       1978\n",
      "1457       2340       1941\n",
      "1458       1078       1950\n",
      "1459       1256       1965\n",
      "\n",
      "[365 rows x 2 columns]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-ed5c4534bd40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#学習\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mlr_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#推定\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#学習データの分割数\n",
    "n=4\n",
    "#モデル数\n",
    "m=2\n",
    "\n",
    "# データを分割し、変数に格納\n",
    "X_0 = np.array_split(X, n, 0)\n",
    "y_0 = np.array_split(y, n, 0)\n",
    "print(X_0)\n",
    "\n",
    "for i in range(n):\n",
    "    \n",
    "    dtr = DecisionTreeRegressor(max_depth=3)\n",
    "    dtr.fit(X_0[i], y_0[i])#学習\n",
    "    dtr_predict = dtr.predict(X_0[i])#推定\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "for j in range(n):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X[j], y[j])#学習\n",
    "    lr_predict = lr.predict(X[-1])#推定\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacking():\n",
    "    def fit():\n",
    "    def predict():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "314px",
    "width": "248px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246.352px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
