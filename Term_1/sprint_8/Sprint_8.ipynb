{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint アンサンブル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:49:54.766893Z",
     "start_time": "2019-10-26T06:49:54.605335Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:50:09.125261Z",
     "start_time": "2019-10-26T06:50:09.099331Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df[[\"GrLivArea\", \"YearBuilt\"]].values\n",
    "y = df[\"SalePrice\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:50:20.753056Z",
     "start_time": "2019-10-26T06:50:20.749063Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:50:42.112602Z",
     "start_time": "2019-10-26T06:50:42.100634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰 MSE : 2495554898.6683216\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_y_pred = lr.predict(X_test)\n",
    "print(\"線形回帰 MSE : {}\".format(mean_squared_error(y_test, lr_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:50:55.068961Z",
     "start_time": "2019-10-26T06:50:54.947285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM MSE : 7861854841.842987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ykenk\\Anaconda3\\envs\\tf_keras\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svm = SVR()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_y_pred = svm.predict(X_test)\n",
    "print(\"SVM MSE : {}\".format(mean_squared_error(y_test, svm_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:51:12.650858Z",
     "start_time": "2019-10-26T06:51:12.643828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "決定木 MSE : 2115019610.5217845\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train, y_train)\n",
    "tree_y_pred = tree.predict(X_test)\n",
    "print(\"決定木 MSE : {}\".format(mean_squared_error(y_test, tree_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】ブレンディングのスクラッチ実装\n",
    "ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:51:37.607272Z",
     "start_time": "2019-10-26T06:51:37.600290Z"
    }
   },
   "outputs": [],
   "source": [
    "def blend(X_train, X_test, y_train, model1, model2):\n",
    "    model1.fit(X_train, y_train)\n",
    "    model1_pred = model1.predict(X_test)\n",
    "    \n",
    "    model2.fit(X_train, y_train)\n",
    "    model2_pred = model2.predict(X_test)\n",
    "    y_pred = (model1_pred + model2_pred) / 2\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:51:49.226098Z",
     "start_time": "2019-10-26T06:51:49.210103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   線形回帰     MSE : 2495554898.6683216\n",
      "      SVM       MSE : 7861854841.842987\n",
      "    決定木      MSE : 2115019610.5217845\n",
      "線形回帰+決定木 MSE : 1890511222.7814226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 線形回帰と決定木の予測結果の平均を予測値とする\n",
    "y_pred = blend(X_train, X_test, y_train, lr, tree)\n",
    "print(\"   線形回帰     MSE : {}\".format(mean_squared_error(y_test, lr_y_pred)))\n",
    "print(\"      SVM       MSE : {}\".format(mean_squared_error(y_test, svm_y_pred)))\n",
    "print(\"    決定木      MSE : {}\".format(mean_squared_error(y_test, tree_y_pred)))\n",
    "print(\"線形回帰+決定木 MSE : {}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:52:00.451003Z",
     "start_time": "2019-10-26T06:52:00.334317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "線形回帰   MSE : 2495554898.6683216\n",
      "SVM        MSE : 7861854841.842987\n",
      "決定木     MSE : 2115019610.5217845\n",
      "SVM+決定木 MSE : 3376643804.7117834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ykenk\\Anaconda3\\envs\\tf_keras\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVMと決定木の予測結果の平均を予測値とする\n",
    "y_pred = blend(X_train, X_test, y_train, svm, tree)\n",
    "print(\"線形回帰   MSE : {}\".format(mean_squared_error(y_test, lr_y_pred)))\n",
    "print(\"SVM        MSE : {}\".format(mean_squared_error(y_test, svm_y_pred)))\n",
    "print(\"決定木     MSE : {}\".format(mean_squared_error(y_test, tree_y_pred)))\n",
    "print(\"SVM+決定木 MSE : {}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:52:14.398965Z",
     "start_time": "2019-10-26T06:52:14.280282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   線形回帰     MSE : 2495554898.6683216\n",
      "      SVM       MSE : 7861854841.842987\n",
      "    決定木      MSE : 2115019610.5217845\n",
      "SVM 線形+多項式 MSE : 4450951532.463163\n"
     ]
    }
   ],
   "source": [
    "# SVMの線形カーネルと多項式カーネルのモデルの予測の平均\n",
    "model1 = SVR(gamma='scale', kernel='linear')\n",
    "model2 = SVR(gamma='scale') \n",
    "y_pred = blend(X_train, X_test, y_train, model1, model2)\n",
    "print(\"   線形回帰     MSE : {}\".format(mean_squared_error(y_test, lr_y_pred)))\n",
    "print(\"      SVM       MSE : {}\".format(mean_squared_error(y_test, svm_y_pred)))\n",
    "print(\"    決定木      MSE : {}\".format(mean_squared_error(y_test, tree_y_pred)))\n",
    "print(\"SVM 線形+多項式 MSE : {}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:45:05.217508Z",
     "start_time": "2019-10-26T06:45:05.206536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      " 3214243459.650467\n",
      "DecisionTree\n",
      " 3009856794.286149\n",
      "SVR\n",
      " 9343844380.188307\n",
      "Blend\n",
      " 3756024787.423033\n"
     ]
    }
   ],
   "source": [
    "print(\"LogisticRegression\\n\",mean_squared_error(t_test, y_lr))\n",
    "print(\"DecisionTree\\n\", mean_squared_error(t_test, y_dt))\n",
    "print(\"SVR\\n\", mean_squared_error(t_test, y_svr))\n",
    "print(\"Blend\\n\",mean_squared_error(t_test, blending_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】バギングのスクラッチ実装\n",
    "バギング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:52:52.568472Z",
     "start_time": "2019-10-26T06:52:52.287213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    決定木      MSE : 2115019610.5217845\n",
      "bagging 決定木  MSE : 2164721843.0078597\n"
     ]
    }
   ],
   "source": [
    "def bagging(X_train, X_test, y_train, model, n=2):\n",
    "    y_pred = np.zeros(X_test.shape[0])\n",
    "    for i in range(n):\n",
    "        X_divided = train_test_split(X_train, random_state=random.randint(0, i))[0]\n",
    "        y_divided = train_test_split(X_train, random_state=random.randint(0, i))[0]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred += model.predict(X_test)\n",
    "    y_pred = y_pred / n\n",
    "    return y_pred\n",
    "\n",
    "y_pred = bagging(X_train, X_test, y_train, tree, n=100)\n",
    "\n",
    "print(\"    決定木      MSE : {}\".format(mean_squared_error(y_test, tree_y_pred)))\n",
    "print(\"bagging 決定木  MSE : {}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:45:32.409783Z",
     "start_time": "2019-10-26T06:45:32.303070Z"
    }
   },
   "source": [
    "# 【問題3】スタッキングのスクラッチ実装¶\n",
    "スタッキング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:54:04.821345Z",
     "start_time": "2019-10-26T06:54:04.806346Z"
    }
   },
   "outputs": [],
   "source": [
    "class Stacking():\n",
    "    def __init__(self, split_n=3, model_n=2):\n",
    "        self.split_n = split_n\n",
    "        self.model_n = model_n\n",
    "\n",
    "    def fit(self, X_train, y_train, X_test, y_test, models):\n",
    "        # K個に分割するdividerを作る\n",
    "        divider = np.zeros(self.split_n)\n",
    "        vol = X_train.shape[0]\n",
    "        num = self.split_n\n",
    "        for i in range(self.split_n):\n",
    "            divider[i] = math.ceil(vol/num)\n",
    "            num -= 1\n",
    "            vol = vol-divider[i]\n",
    "        \n",
    "        self.divider = divider.astype(int)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.models = models\n",
    "        print(self.divider)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        for m in range(self.model_n):\n",
    "            divide_point = 0\n",
    "            for n in range(self.split_n):\n",
    "                idx = np.zeros(X_train.shape[0], dtype=bool)\n",
    "                idx[divide_point:divide_point+self.divider[n]]= True\n",
    "                self.X_test_divided = X_train[idx, :]\n",
    "                self.X_train_divided = X_train[~idx, :]\n",
    "                self.y_test_divided = y_train[idx]\n",
    "                self.y_train_divided = y_train[~idx]                    \n",
    "                \n",
    "                models[m].fit(self.X_train_divided, self.y_train_divided)\n",
    "                if n == 0:\n",
    "                    blend = models[m].predict(self.X_test_divided)\n",
    "                    pred_data = models[m].predict(X_test)\n",
    "                else:\n",
    "                    blend = np.r_[blend, models[m].predict(self.X_test_divided)]\n",
    "                    pred_data = np.c_[pred_data, models[m].predict(X_test)]\n",
    "            \n",
    "                divide_point += self.divider[n]\n",
    "            if m ==0:\n",
    "                blend_data =blend.reshape(-1, 1)\n",
    "                blend_pred_data = np.mean(pred_data, axis=1)\n",
    "            else:\n",
    "                blend_data = np.c_[blend_data, blend.reshape(-1, 1) ]\n",
    "                blend_pred_data = np.c_[blend_pred_data, np.mean(pred_data, axis=1)]\n",
    "        \n",
    "        models[0].fit(blend_data, y_train)\n",
    "        y_pred = models[0].predict(blend_pred_data)                               \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T06:54:19.948054Z",
     "start_time": "2019-10-26T06:54:19.917138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[390 389 389]\n",
      "線形回帰 MSE : 2495554898.6683216\n",
      "SVM      MSE : 7861854841.842987\n",
      "決定木   MSE : 2115019610.5217845\n",
      "Stacking MSE : 1905881409.1172748\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "models = [LinearRegression(), DecisionTreeRegressor()]\n",
    "\n",
    "stacking = Stacking()\n",
    "stacking.fit(X_train, y_train, X_test, y_test, models)\n",
    "y_pred = stacking.predict(X_test)\n",
    "\n",
    "print(\"線形回帰 MSE : {}\".format(mean_squared_error(y_test, lr_y_pred)))\n",
    "print(\"SVM      MSE : {}\".format(mean_squared_error(y_test, svm_y_pred)))\n",
    "print(\"決定木   MSE : {}\".format(mean_squared_error(y_test, tree_y_pred)))\n",
    "print(\"Stacking MSE : {}\".format(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
