{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T04:33:53.103187Z",
     "start_time": "2019-10-20T04:33:38.952812Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】コードレビュー\n",
    "転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。\n",
    "\n",
    "《視点例》\n",
    "\n",
    "前回使用した実装とはどのように違うのか\n",
    "転移学習をどのように行っているか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "# ボトルネックアーキテクチャを備えたデコーダーブロック。表現を圧縮するために、\n",
    "# 中間コンバージョンレイヤーが最初と最後の半分のサイズです。 \n",
    "# このタイプのアーキテクチャは、最も有用な情報を保持することになっています。\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "# モデルは、decoder_blockタイプを簡単に変更できるようにパラメーター化されます。\n",
    "# これは、decoder_block_simpleなどの関数を指定できる引数であるためです。\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    # エンコーダー部分での特徴抽出のためのレイヤー\n",
    "    encoder1 = base_model.get_layer('activation_1').output\n",
    "    encoder2 = base_model.get_layer('activation_10').output\n",
    "    encoder3 = base_model.get_layer('activation_22').output\n",
    "    encoder4 = base_model.get_layer('activation_40').output\n",
    "    encoder5 = base_model.get_layer('activation_49').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    #デコーダー部分。 \n",
    "    #すべてのデコーダーブロックは、エンコーダーとデコーダー部分からの連結出力を処理しました。 \n",
    "    #これはスキップ接続を作成します。 \n",
    "    #その後、デコーダー出力は、エンコーダー出力部分に等しい次元にアップサンプリングされます。\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コードリーディング\n",
    "・5行目～9行目：decoder_blockタイプを容易に変更できるようunet_resnet関数の引数に設定されている。  \n",
    "・5行目～9行目：unet_resnetの引数で重みがimagenetで学習済みのものを使用するよう設定されている。(転移学習）  \n",
    "・11行目～15行目：前回（U-net ）では各層ごとにに書かれていたが、resnetでは転移学習を行うためにencoder部分を各層ごとにインスタンス化している。  \n",
    "・25～28行目：U字の最下層部分,center部分畳み込み層、バッチノーマライゼーション（正規化）、PRELU活性化関数を通し、centerレイヤーとencoder5レイヤーを連結している。  \n",
    "・38行目～52行目：デコーダー部分。各層でdecoder_block（CNN）処理し、upsamplingしencoder層の出力と連結している（スキップ処理を行っている）。\n",
    "それを各層で行っている。  \n",
    "・56～62行目：出力層ではスキップ処理してものを受け取り、upsamplingし、CNN処理して、畳み込み処理している。\n",
    "loss関数がuse_lovashなら恒等関数、loss関数がuse_lovashを使わないなら活性化関数をsigmoidとし、二値分類なのでクラス数を1として出力するようにしている。  \n",
    "・64～67行目：functionalAPIで入力をbase_modelとし、Modelをインスタンス化し、コンパイルし、modelを返している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 【問題2】コードの書き換え\n",
    "エンコーダーにResNetが使用されていたコードをVGGに変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T14:51:58.408331Z",
     "start_time": "2019-10-20T14:51:58.292627Z"
    },
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"unet_resnetをunet_vggに書き換え\"\"\"  \n",
    "def unet_vgg(input_size, decoder_block,  \n",
    "               weights='imagenet',  \n",
    "                loss_func='binary_crossentropy',  \n",
    "                metrics_list=[my_iou_metric],  \n",
    "                use_lovash=False):  \n",
    "\n",
    "    # Base model - encoder  \n",
    "    '''ResNet50をVGG16に書き換え'''\n",
    "    base_model = VGG16(  \n",
    "        input_shape=input_size,   \n",
    "        include_top=False,  \n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    # エンコーダー部分での特徴抽出のためのレイヤー\n",
    "    \"\"\"layernameを書き換え\"\"\"\n",
    "    encoder1 = base_model.get_layer('block1_conv2').output\n",
    "    encoder2 = base_model.get_layer('block2_conv2').output\n",
    "    encoder3 = base_model.get_layer('block3_conv3').output\n",
    "    encoder4 = base_model.get_layer('block4_conv3').output\n",
    "    encoder5 = base_model.get_layer('block5_conv3').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】学習・推定\n",
    "ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# すいません、現状ここまでです。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
